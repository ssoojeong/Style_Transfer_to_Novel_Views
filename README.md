# Style Transfer to Novel Views using Correspondences between Photos and Sketches 

## &#x1F4E2; Project Overview: 2404~2406

### ğŸ“„ í”„ë¡œì íŠ¸ ê°œìš”

![intro](./figure/intro.png)
- ì´ë¯¸ì§€ì˜ ì‹œì (êµ¬ë„)ì„ ë³€í™˜í•œ í›„ ì‚¬ìš©ì ì·¨í–¥ì— ë§ì¶˜ ìŠ¤íƒ€ì¼ ì „ì´ë¥¼ ìˆ˜í–‰
- ìŠ¤ì¼€ì¹˜ ì´ë¯¸ì§€ë¥¼ í™œìš©í•´ ì‚¬ìš©ìê°€ ì›í•˜ëŠ” íŠ¹ì • ìƒˆë¡œìš´ ì‹œì ì„ ì‰½ê²Œ í‘œí˜„í•¨
- ì´í›„ ìŠ¤íƒ€ì¼ ì „ì´ë¥¼ í†µí•´ ë”ìš± ê°œê°œì¸ì˜ ì·¨í–¥ì— ì»¤ìŠ¤í„°ë§ˆì´ì§•í•œ ì‹œê°ì  ì½˜í…ì¸ ë¥¼ ìƒì„±
- ì´ ê¸°ìˆ ì„ í†µí•´ ì¦ê°• í˜„ì‹¤(AR), ê°€ìƒ í˜„ì‹¤(VR) ë“±ì˜ í™˜ê²½ì—ì„œ ì‚¬ìš©ìì˜ ì‹œê°ì  ê²½í—˜ì„ í–¥ìƒì‹œí‚¤ê³ ì í•¨

### ğŸ¯ í”„ë ˆì„ì›Œí¬
![framework](./figure/framework.png)
![framework](./figure/warping.png)
1. Semantic Correspondence Point Searching & Image Warping
    - í”¼ì²˜ ì¶”ì¶œ ë° ë§¤ì¹­: ì‚¬ì „ í•™ìŠµëœ MoCo ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•´ ì‚¬ì§„ê³¼ ìŠ¤ì¼€ì¹˜ ì´ë¯¸ì§€ì—ì„œ í”¼ì²˜ë¥¼ ì¶”ì¶œí•˜ê³ , UV ë§µ ê¸°ë°˜ ë§¤ì¹­ ìˆ˜í–‰
    - ì´ë¯¸ì§€ ì›Œí•‘ (Image Warping): Spatial Transformer Network (STN)ì„ ì‚¬ìš©í•´ ì¶”ì •ëœ ì½”ë ˆìŠ¤í°ë˜ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ ì›Œí•‘

![framework](./figure/style_transfer.png)
2. Image-to-Image Style Transfer
    - ì›Œí•‘ëœ ì´ë¯¸ì§€ì™€ ìŠ¤íƒ€ì¼ ì´ë¯¸ì§€ë¥¼ VGG19 ëª¨ë¸ì— ì…ë ¥í•˜ì—¬, ì‚¬ìš©ì ì·¨í–¥ì— ë§ëŠ” ìµœì¢… stylized image ìƒì„±

### ğŸ“Š ì‹¤í—˜ ì„¤ì •
#### ë°ì´í„°ì…‹
- Photo-Sketchy database from [Link](https://github.com/cogtoolslab/photo-sketch-correspondence/blob/main/PSC6K_Benchmark_README.md)
- Wikiart dataset from [github](https://github.com/cs-chan/ArtGAN/blob/master/WikiArt%20Dataset/README.md) or [kaggle](https://www.kaggle.com/datasets/steubk/wikiart)

#### í‰ê°€ ì§€í‘œ
- Percentage of Correct Keypoints (PCK): semantic correspondence ë§¤ì¹­ í‰ê°€ 
- KNN accuracy: warping ì„±ëŠ¥ í‰ê°€
- VGG Content Loss, VGG Style Loss: ìŠ¤íƒ€ì¼ ì „ì´ ì„±ëŠ¥ í‰ê°€

----

### ğŸ“ ì‹¤í—˜ ê²°ê³¼
1. Quantitative Results:
    - ì´ë¯¸ì§€ ì›Œí•‘: ë†’ì€ PCKì™€ KNN ì •í™•ë„ë¥¼ ë³´ì—¬, íš¨ê³¼ì ì¸ ì‹œì  ë³€í™˜ì„ ì…ì¦
    - ìŠ¤íƒ€ì¼ ì „ì´: VGG Content Lossì™€ Style Lossë¥¼ í†µí•´ ì‚¬ì§„ ì´ë¯¸ì§€ê°€ ìŠ¤ì¼€ì¹˜ ì´ë¯¸ì§€ë³´ë‹¤ ë” ë‚˜ì€ ìŠ¤íƒ€ì¼ ì „ì´ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²ƒì„ í™•ì¸
2. Qualitative Results:
    - ìŠ¤ì¼€ì¹˜ì™€ ì‚¬ì§„ ì´ë¯¸ì§€ ê°„ì˜ íš¨ê³¼ì ì¸ ì‹œë§¨í‹± ë§¤ì¹­ í™•ì¸
    - stylized imagesì—ì„œëŠ” ìì—°ìŠ¤ëŸ½ê³  ì‹œê°ì ìœ¼ë¡œ ì¼ê´€ì„±ìˆëŠ” ìŠ¤íƒ€ì¼ì„ í™•ì¸í•¨

### ğŸ” ë¬¸ì œ ë¶„ì„
![framework](./figure/problem.png)
- ë³¸ ë°©ë²•ì—ì„œëŠ” Fundamental Matrix ì¶”ì •ì˜ í•œê³„ë¡œ ì¸í•´ ì‹œë§¨í‹± ì½”ë ˆìŠ¤í°ë˜ìŠ¤ì˜ ì •í™•ë„ê°€ ë‚®ì•„ì§€ëŠ” ë¬¸ì œê°€ ìˆìŒ

![framework](./figure/problem2.png)
- ìŠ¤ì¼€ì¹˜ ì´ë¯¸ì§€ëŠ” ìƒ‰ìƒ ì •ë³´ê°€ ë¶€ì¡±í•´ ìŠ¤íƒ€ì¼ ì „ì´ ì„±ëŠ¥ì´ ë‚®ì•˜ìŒ

### ğŸ“ˆ Ablation Study
- Epipolar Constraint Loss: Epipolar ì œì•½ ì†ì‹¤ì„ ì¶”ê°€í–ˆì„ ë•Œ ì‹œë§¨í‹± ë§¤ì¹­ì´ ê°œì„ ë˜ì—ˆì§€ë§Œ, Fundamental Matrix ì¶”ì • ë¬¸ì œë¡œ ì¸í•´ KNN ì •í™•ë„ê°€ ë‚®ì•„ì§
- ëŒ€ì²´ ìŠ¤íƒ€ì¼ ì „ì´ ë°©ë²•: ìƒ‰ìƒ, ê¹Šì´ ì •ë³´ ë“±ì˜ ì¶”ê°€ ì»¨ë””ì…”ë‹ ì…ë ¥ì„ ì‚¬ìš©í•˜ê±°ë‚˜, ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ ì „ì´ ëª¨ë¸ì„ ì ìš©í•¨ìœ¼ë¡œì¨ ì„±ëŠ¥ í–¥ìƒ ê¸°ëŒ€


### ğŸš€ í–¥í›„ ì—°êµ¬ ë°©í–¥
- Fundamental Matrix ì¶”ì • ì •í™•ì„±ì„ í–¥ìƒì‹œì¼œ ì™œê³¡ ë¬¸ì œë¥¼ ì¤„ì´ëŠ” ë°©ë²•ì„ íƒêµ¬
- ìƒ‰ìƒ ë° ê¹Šì´ ì •ë³´ì™€ ê°™ì€ ì¶”ê°€ ì»¨ë””ì…”ë‹ ì…ë ¥ì„ í™œìš©í•˜ì—¬ ìŠ¤ì¼€ì¹˜ ì´ë¯¸ì§€ì˜ ìŠ¤íƒ€ì¼ ì „ì´ ì„±ëŠ¥ ê°œì„  ë„ëª¨
- ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ ì „ì´ ëª¨ë¸ê³¼ ë°ì´í„°ì…‹ì„ í‰ê°€í•˜ì—¬ ë” ë„“ì€ ì‘ìš© ê°€ëŠ¥ì„± íƒìƒ‰

----

## ğŸ“š References

[PDF Report](./project_report_final.pdf), 
[PPT Report](./project_report_final_ppt.pdf)

| **Title**                                                                                                                      | **Conference/Journal**        | **Year** |
|-------------------------------------------------------------------------------------------------------------------------------|-------------------------------|----------|
| *"Image Style Transfer Using Convolutional Neural Networks."*                                                                 | CVPR                          | 2016     |
| *"Learning Dense Correspondences between Photos and Sketches."*                                                               | ICML (PMLR)                   | 2023     |
| *"Self-Supervised Learning of Semantic Correspondence Using Web Videos."*                                                     | WACV                          | 2024     |

